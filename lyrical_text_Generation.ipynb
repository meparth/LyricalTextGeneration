{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final lyrical text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qml7Iv9sKwYG",
        "colab_type": "text"
      },
      "source": [
        "#Lyrics Generation using  Character level RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsvMU7Q7KwzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e0-WjtbEbhv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKc2CJilRWYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOGCa5JDK17n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from IPython import display\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4kame7P215c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK3wy8XmLM1d",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52KWKp--LRVH",
        "colab_type": "code",
        "outputId": "1151d3c4-b276-4347-f9d5-57f196e4e69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "import string\n",
        "import random\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "def DownloadFile(url):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    r = requests.get(url)\n",
        "    return r.text\n",
        "\n",
        "def char_tensor(string):\n",
        "   \n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        except:\n",
        "            \n",
        "            continue\n",
        "    return tensor  \n",
        "\n",
        "def random_training_set(chunk_len, batch_size, file):\n",
        "     '''\n",
        "     TODO: Convert to stateful LSTM with more features\n",
        "     '''\n",
        "     inp = torch.LongTensor(batch_size, chunk_len)\n",
        "     target = torch.LongTensor(batch_size, chunk_len)\n",
        "     file_len = len(file)\n",
        "\n",
        "     for bi in range(batch_size):\n",
        "\n",
        "          start_index = random.randint(0, file_len - chunk_len)\n",
        "          end_index = start_index + chunk_len + 1\n",
        "          chunk = file[start_index:end_index]\n",
        "          \n",
        "               \n",
        "          inp[bi] = char_tensor(chunk[:-1])\n",
        "          target[bi] = char_tensor(chunk[1:])\n",
        "\n",
        "     inp = Variable(inp)\n",
        "     target = Variable(target)\n",
        "\n",
        "     if use_cuda:\n",
        "          inp = inp.cuda()\n",
        "          target = target.cuda()\n",
        "\n",
        "     return inp, target\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# target_url = \"https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt\"\n",
        "target_url = \"https://raw.githubusercontent.com/Blaziking/Lyrics-generation-using-Ngrams/master/Dylan%2C%20Bob%20Lyrics%2C%201962-2001%20-%20preprocessed.txt\"\n",
        "\n",
        "data = DownloadFile(target_url)\n",
        "#print(random_training_set(10, 8, data))\n",
        "print(data[90:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ht I’d see\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv0_yL--JflG",
        "colab_type": "code",
        "outputId": "978f2fd4-00a4-43cc-e7bb-0665128cf3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(data[:186])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n",
            "Talking New York\n",
            "\n",
            "\n",
            "Ramblin’ outa the wild West\n",
            "\n",
            "Leavin’ the towns I love the best\n",
            "\n",
            "Thought I’d seen some ups and downs\n",
            "\n",
            "’Til I come into New York town\n",
            "\n",
            "People goin’ down to the ground\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRqDgnoYKvOM",
        "colab_type": "code",
        "outputId": "059fcb66-a1a9-4b89-c9d9-0f3d7c86eb81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "903947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw7E1yvHPbMD",
        "colab_type": "text"
      },
      "source": [
        "#Model\n",
        "In this code we use Pytorch already implemented Recurrent Neural Network Cell computation with `nn.RNN` and `nn.LSTM`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjolCWdP1fkS",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM-RJy9gNcT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/spro/char-rnn.pytorch\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, model=\"rnn\", n_layers=1):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.model = model.lower()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
        "        if model==\"lstm\":\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "          \n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        batch_size = input.size(0)\n",
        "        encoded = self.encoder(input)\n",
        "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
        "        output = self.dropout(output)\n",
        "        output = self.decoder(output.view(batch_size, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.model == \"lstm\":\n",
        "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
        "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
        "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB9xsWiEQhkU",
        "colab_type": "text"
      },
      "source": [
        "###Iinitialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDV_0GRbLtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 100\n",
        "learning_rate = 0.005\n",
        "cell = \"rnn\"\n",
        "n_layers = 2\n",
        "\n",
        "decoder = CharRNN(\n",
        "    n_characters,\n",
        "    hidden_size,\n",
        "    n_characters,\n",
        "    model=cell,\n",
        "    n_layers=n_layers,\n",
        ")\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if use_cuda:\n",
        "    decoder.cuda()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRdaN2-FRndV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 2000\n",
        "chunk_len = 200\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KPmkvGJPkNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden(batch_size)\n",
        "    if use_cuda:\n",
        "      if isinstance(hidden, tuple):\n",
        "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "      else:\n",
        "            hidden = hidden.cuda()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[:,c], hidden)\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data[0] / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8M-FSO-TTLF",
        "colab_type": "text"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh4cIaRDS23s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
        "    hidden = decoder.init_hidden(1)\n",
        "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
        "    \n",
        "    if cuda:\n",
        "      if isinstance(hidden, tuple):\n",
        "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "      else:\n",
        "            hidden = hidden.cuda()\n",
        "    \n",
        "    if cuda:\n",
        "        prime_input = prime_input.cuda()\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\n",
        "        \n",
        "    inp = prime_input[:,-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
        "        if cuda:\n",
        "            inp = inp.cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXDDbny1-DF",
        "colab_type": "code",
        "outputId": "d9a9f846-8670-4388-db9c-a320eb7679ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3128
        }
      },
      "source": [
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "print(\"Training for %d epochs...\" % n_epochs)\n",
        "for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "    loss = train(*random_training_set(chunk_len, batch_size, data))\n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print('loss: ', loss)\n",
        "        print(generate(decoder, 'H', 100, cuda=use_cuda), '\\n')\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / print_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training for 2000 epochs...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [00:45<15:09,  2.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0m 45s (100 5%) 1.8379]\n",
            "loss:  1.8378939819335938\n",
            "He wald a beatrow that stat to dead\n",
            "\n",
            "A a ending jut hor that we\n",
            "\n",
            "Noed ir to you0ll a call\n",
            "\n",
            "I peade ma \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [01:31<14:00,  2.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1m 31s (200 10%) 1.7895]\n",
            "loss:  1.7894905090332032\n",
            "He satter can0t were to the can trough my alase\n",
            "\n",
            "The bonsty of gannin0 he0s wonders, 0Ning\n",
            "\n",
            "Treved co \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [02:17<13:17,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2m 17s (300 15%) 1.6451]\n",
            "loss:  1.6450860595703125\n",
            "Him\n",
            "\n",
            "When you, roll I shothin0 fawn you0ll gabery doof\n",
            "\n",
            "How\n",
            "\n",
            "Things back bind\n",
            "\n",
            "The stace\n",
            "\n",
            "0hout ten s \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [03:03<12:25,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3m 3s (400 20%) 1.6013]\n",
            "loss:  1.6013270568847657\n",
            "He prome wom end bcound me thinks a little will be the wantle that thinking down her unreet bust have \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [03:49<11:43,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3m 49s (500 25%) 1.5832]\n",
            "loss:  1.5831800842285155\n",
            "Her was bad and the sun was tomes on just dones be see down of the done\n",
            "\n",
            "When I do I the wettern toni \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [04:35<11:00,  2.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4m 35s (600 30%) 1.5389]\n",
            "loss:  1.5389125061035156\n",
            "Her your done was bed my nead in friends hall is\n",
            "\n",
            "I go\n",
            "\n",
            "That somethin0 for you\n",
            "\n",
            "Well, the Can say Jac \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [05:21<10:43,  2.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[5m 21s (700 35%) 1.5331]\n",
            "loss:  1.5331491088867188\n",
            "He carced away\n",
            "\n",
            "True my feeled my diasons will now, the night\n",
            "\n",
            "I0m jolites\n",
            "\n",
            "To tree\n",
            "\n",
            "You all the did  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 800/2000 [06:07<09:48,  2.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[6m 7s (800 40%) 1.5203]\n",
            "loss:  1.5203265380859374\n",
            "Had Ened\n",
            "\n",
            "Could overthip comes this hure?\n",
            "\n",
            "Well, I0m ready\n",
            "\n",
            "Fats\n",
            "\n",
            "This way you0re hid ma He0s drown f \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 900/2000 [06:53<08:32,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[6m 53s (900 45%) 1.4935]\n",
            "loss:  1.4935354614257812\n",
            "Hey been the beron\n",
            "\n",
            "Well, Gy!\n",
            "\n",
            "\n",
            "I been a-tellly I0m got no pise\n",
            "\n",
            "But that0s like he sit I0m over is d \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1000/2000 [07:39<07:51,  2.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7m 39s (1000 50%) 1.5117]\n",
            "loss:  1.5117115783691406\n",
            "Hen that closerin0 you all at million in my let I got a breath you walkin0 to so for out of the sun i \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1100/2000 [08:25<06:56,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[8m 25s (1100 55%) 1.4998]\n",
            "loss:  1.4997879028320313\n",
            "Hen baid of back up at you that no Blue Crow\n",
            "\n",
            "Baby\n",
            "\n",
            "Welre don0t just lookin0 abody beth concas her ti \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1200/2000 [09:10<06:14,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 10s (1200 60%) 1.4843]\n",
            "loss:  1.4843319702148436\n",
            "He was on a do\n",
            "\n",
            "You mother by their good the morner or like his body so lose me\n",
            "\n",
            "The judge far in an  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1300/2000 [09:56<05:28,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 56s (1300 65%) 1.5078]\n",
            "loss:  1.5078059387207032\n",
            "Her mothing\n",
            "\n",
            "And then by a think is no distance the passed on badsy, I, I got her chead\n",
            "\n",
            "Oh, once\n",
            "\n",
            "An \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1400/2000 [10:42<04:50,  2.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10m 42s (1400 70%) 1.5167]\n",
            "loss:  1.5166665649414062\n",
            "Hispered of love\n",
            "\n",
            "In a-time about talkin0 sumpeaning\n",
            "\n",
            "To hears stoling ponnagg\n",
            "\n",
            "I can0t or stite chop \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1500/2000 [11:28<03:56,  2.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[11m 28s (1500 75%) 1.4628]\n",
            "loss:  1.4628276062011718\n",
            "He was rolling like upleth Down\n",
            "\n",
            "Trouble my an0 hold\n",
            "\n",
            "They been because you0ll make you\n",
            "\n",
            "God I was pl \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1600/2000 [12:14<03:08,  2.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12m 14s (1600 80%) 1.4782]\n",
            "loss:  1.4781565856933594\n",
            "Hang that you shoughteard the forging the rage the one of the beator the rarad\n",
            "\n",
            "Took him on old mind, \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1700/2000 [13:00<02:19,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13m 0s (1700 85%) 1.4619]\n",
            "loss:  1.4618914794921876\n",
            "Heress age sitce to the jiscaning every a-gorn\n",
            "\n",
            "I love it back about\n",
            "\n",
            "I can0t get right\n",
            "\n",
            "Ain0t you go \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1800/2000 [13:46<01:32,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13m 46s (1800 90%) 1.4238]\n",
            "loss:  1.4237648010253907\n",
            "He thing\n",
            "\n",
            "If you got up to me\n",
            "\n",
            "With you to his child the sunderty soned old polenty peoplense for the \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1900/2000 [14:32<00:47,  2.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14m 32s (1900 95%) 1.4684]\n",
            "loss:  1.468448486328125\n",
            "Hard to your head of their hand\n",
            "\n",
            "You know I see the land\n",
            "\n",
            "To sea out for your thinking the judge, the \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [15:17<00:00,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15m 17s (2000 100%) 1.4557]\n",
            "loss:  1.455680389404297\n",
            "Head\n",
            "\n",
            "You, your way at eyes that must back for?\n",
            "\n",
            "With a lot!\n",
            "\n",
            "Well, I0ll be here me a spard\n",
            "\n",
            "You can  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qegUIg2u8WpP",
        "colab_type": "text"
      },
      "source": [
        "###Plotting the losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frb0B82J9Vzq",
        "colab_type": "code",
        "outputId": "4ada8aa9-1d54-47d9-f356-ae42514bf5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "plt.figure()\n",
        "plt.plot(all_losses, label=\"\"\"dylan Dataset\"\"\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f92aaf2a588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f92b15275f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7snNirbPzaDk",
        "colab_type": "text"
      },
      "source": [
        "## Let's try sampling with different temperature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oCPS6kzRK4w",
        "colab_type": "code",
        "outputId": "f23bc333-19a6-4209-9a18-7e60291ef53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I \", temperature= 100, cuda=use_cuda)) # temperature = 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I [~k94\\W5||\r5STA,M<*?EiDL&a*\u000b-p73{R`VC}\"bzBQy{/r\rqOM.\r:KK~gcOMZXM|*Re%E@7\u000b)wgUy!3(AD\n",
            "\n",
            "SE\rvl\\rG_B`hg\u000bN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPrAwVItSyyv",
        "colab_type": "code",
        "outputId": "3157ba31-3905-4a6e-d11e-217b8426af60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I \", temperature=0.8 , cuda=use_cuda)) # temperature = .8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I state.\r\n",
            "But is a very soction is one of their. Our -- they don0t know what thall have allecantracy a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnM6T7QzS44v",
        "colab_type": "code",
        "outputId": "e197565e-fe4c-485e-bd10-586770156594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I \", temperature=.4 , cuda=use_cuda)) # temperature = .4 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have to the poor gone to stay you got my life breather\n",
            "\n",
            "I0m gonna give the where the man to the wind\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr7XIKpnTG33",
        "colab_type": "code",
        "outputId": "fa3cc8cc-aeca-4871-f3a0-1eda790e21c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"He\", temperature=.34 , cuda=use_cuda, predict_len = 500)) # temperature = .3 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He prother tell you the shore\n",
            "\n",
            "She said the morning\n",
            "\n",
            "To be what I got to see the wind of separy life when you can0t see me to see you a got the bark in the mind in bed who knows the way if I was the change of the back\n",
            "\n",
            "I can0t see the chain\n",
            "\n",
            "When you gonna had to get and the missise\n",
            "\n",
            "Well, the country\n",
            "\n",
            "When the dead with a door\n",
            "\n",
            "I said, 0You can0t she said, 0I0ll know the skin for the stare\n",
            "\n",
            "Can0t stand alone\n",
            "\n",
            "The could have to do word\n",
            "\n",
            "Well, the should you can0t see me\n",
            "\n",
            "But I0m what I0m so the tr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1jC_PzWTOFa",
        "colab_type": "code",
        "outputId": "0ed486ea-b79c-401a-f04d-309a983a96e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I \", temperature=.1 , cuda=use_cuda)) # temperature = .1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am a starts,, they don0t want the press and they0re going to be a lot of the people,, they0re going \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7gmk7ppUUdQ",
        "colab_type": "code",
        "outputId": "47e956ff-b89b-4585-da21-82d1d4e5e44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I \", temperature=0 , cuda=use_cuda)) # temperature = 0 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I abaa000ab00ab00000000000ab00000000000000000000000000000000000000000000000000000000000000000000000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xND5BVvo1pxa",
        "colab_type": "text"
      },
      "source": [
        "### Example\n",
        "Inserting  a meaningful sentence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkfQIbosztV_",
        "colab_type": "code",
        "outputId": "58b64385-e9d7-48ea-ba21-7573708012f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"Repulican will\", predict_len = 1000, temperature = .34, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Repulican will be all these politics but I would have been the way they could do that stuff and they don0t get the problem in New Hampshire. It0s a country that have been a lot of the press again. We0re going to be the walls on the people don0t want to be a single country but they don0t want to be about the press and they want to be the people are going to happen to do it and they have a lot of people that want to be things that are believe it. They want to be a lot of the thing. I was a great all of the great country and they can0t folks. I want to do to be about the people because they don0t want to say that I was a great country in that was a big a lot of the country. They don0t think the Uridasy. You know what they get the country. They have a tax in the way that is done it and we have to say a better than they0re going to be the people are don0t want to come in the people are like the people that they want to be terrible but they don0t want to the people and they can0t get the problem. I don0t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQ7qbMdXEQ5",
        "colab_type": "code",
        "outputId": "312382fe-f603-4b23-acd6-be1c578ff8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"Infact \", temperature = .34, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Infact us and they don0t know what they don0t know what anywhere that are about the best out of the other a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wh6MrSNXWyQ",
        "colab_type": "code",
        "outputId": "4261a16c-f45a-48b9-b2e1-5bcfeb72bcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"I watch the speeches of these people\", temperature = .34, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I watch the speeches of these people are beautiful and they do that by the way we0re going to have a disasters and don0t have to be a te\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0SlCiLRX4h6",
        "colab_type": "code",
        "outputId": "0469a8de-6ba7-44cf-8aa0-da58996fa1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We have to repeal Obamacare\", temperature = .3, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have to repeal Obamacare. We have to say the statements are the one of the particals. I was a great come in the country in t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMMgmIw8YR7f",
        "colab_type": "code",
        "outputId": "96f875af-60d5-46b0-9174-5fd38942c9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"Make America \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Make America bilding the Wallies that they0ve keep noter and they take into the country buildickly a take care of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBYpYux6ZV7o",
        "colab_type": "code",
        "outputId": "6ddc306d-4916-4d13-d325-e7230fe2218f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader for Obama car everything the bigger and 130,000 and agree ISIS. You know, they0re doing. And that, t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beXJeWvD0-5w",
        "colab_type": "text"
      },
      "source": [
        "#Experiment with Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep3XNDP4zAlK",
        "colab_type": "text"
      },
      "source": [
        "##We need \n",
        "* noun after need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iyrZj8ex0kL",
        "colab_type": "code",
        "outputId": "be8d4f33-515c-483b-a7b0-fc6541b56d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need them and it0s a good leave the Clinton. And I0m going to or the really spect to do in trouble making\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXBavyXIzIYS",
        "colab_type": "code",
        "outputId": "2ff8fd6c-cf69-4444-a766-7880db8e6f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need to see the Moducting to do a change and we have a moneminator were to actually to be knows are didib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCVflgtXy-Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AJwDoy1x_1z",
        "colab_type": "code",
        "outputId": "20093184-fabc-47c8-edb3-91faad2f14bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need our job, and they don0t by the veterpaid from a successful and we se its of our happening and they h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEmTSWchyIUC",
        "colab_type": "code",
        "outputId": "169f6075-35c2-4543-bbb1-223ef6f44a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need the running and just as the time if we0re going to your remember the send some friend, benation that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEjuZXNhz1-v",
        "colab_type": "text"
      },
      "source": [
        "##We need + more spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QvhBUsRz0jA",
        "colab_type": "code",
        "outputId": "7a23815f-8b0d-4b80-a548-3279210ecbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need  \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need  Merboy and then get it.\r\n",
            "And you know, I gave the monitier.\" We0re going to be do trage China. They \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sL5pa430LmT",
        "colab_type": "code",
        "outputId": "2af30356-8d68-457e-cf4c-a66f7e0ebda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need  \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need  in New Press you know what we0re going to find of the usest that he on great people.\r\n",
            "But go to do w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCvGG52F0OTM",
        "colab_type": "code",
        "outputId": "efd0c42c-8e72-4f3a-b40f-63963749f7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need  \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need  Americans. They bad vow you. And then a lot attines that0s go are foreign but aroond. So you send in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K08LlcoS0UMi",
        "colab_type": "code",
        "outputId": "b6bc2561-52c5-4ee4-e302-8123392c5d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need                    \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need                    We don0t could press in they0re while to 0 I0ll be the vets. We have a very, what they don0t have to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDek9wSf0YGD",
        "colab_type": "code",
        "outputId": "577eb91e-7a31-47ac-854f-45936c3775c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need                     \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need                     geneled this the campaign and support but there was was and I was comes. And they0re don0t do it, th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOveg_cpxuBZ",
        "colab_type": "text"
      },
      "source": [
        "#We, need a leader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx6Z5lI3xn70",
        "colab_type": "code",
        "outputId": "f477d2ad-c8c8-4760-87c4-8ff6c6bd7b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader out of the president.\r\n",
            "Now, even the presidence out of their politically, we have tremendous ads sai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69gjmbaSypQS",
        "colab_type": "code",
        "outputId": "db2b98b4-720b-4dcd-efd9-041667533c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader of what is not seen saying everybody is a lot of a people better in.Shishany it world and we0re goin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYQI66B1ywNN",
        "colab_type": "code",
        "outputId": "d203cd5f-7ac5-4fef-c891-1f7e766c0ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader wither of packed on Wountas itterdia. They0re tell into your bay is smope.\r\n",
            "\r\n",
            "\r\n",
            "I whit iago and raw \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXUjE-CnygOi",
        "colab_type": "code",
        "outputId": "5eae66da-29f4-4870-c186-2361c3ada1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader forget to says I do.  They are now with our first. I think that the credit that cameran agreated at \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxXgXqlo1eGw",
        "colab_type": "code",
        "outputId": "c477ca1f-8bad-4b69-bf5c-a6d07de609e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(generate(decoder, prime_str=\"We, need a leader \", temperature = .8, cuda=use_cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We, need a leader of for something to start countries. Very supposed to be a year. But we have all anything here. He0s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}